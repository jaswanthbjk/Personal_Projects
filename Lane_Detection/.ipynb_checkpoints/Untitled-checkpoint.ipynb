{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "ros_path = '/opt/ros/kinetic/lib/python2.7/dist-packages'\n",
    "\n",
    "if ros_path in sys.path:\n",
    "\n",
    "    sys.path.remove(ros_path)\n",
    "\n",
    "import cv2\n",
    "\n",
    "sys.path.append('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Show_Image(img):\n",
    "    cv2.imshow('Image',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting the Line patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Image to Gray Scale\n",
    "image = cv2.imread('./Road_With_Markings.jpeg')\n",
    "image_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "image_hsv = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "#Defining the Highlight colors which are White and Yellow\n",
    "\n",
    "lower_yellow = np.array([20, 100, 100], dtype = 'uint8')\n",
    "upper_yellow = np.array([30, 255, 255], dtype = 'uint8') \n",
    "\n",
    "mask_yellow = cv2.inRange(image_hsv, lower_yellow, upper_yellow)\n",
    "mask_white = cv2.inRange(image_gray, 200, 255)\n",
    "\n",
    "patch = cv2.bitwise_or(mask_yellow,mask_white)\n",
    "\n",
    "patch_image = cv2.bitwise_and(image_gray,patch)\n",
    "\n",
    "imshape = patch_image.shape\n",
    "vertices = np.array([[(int(0.21*imshape[1]),imshape[0]),(int(0.44*imshape[1]), int(0.59*imshape[0])), (int(0.50*imshape[1]), int(0.59*imshape[0])), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clearing the Noise and applying the Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with - Make a black image of the same size\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255# white\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color  \n",
    "    # Fill the defined polygon area with white\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    # Will return only the region of interest\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=3):\n",
    "    # Function has been written to work with Challenge video as well\n",
    "    # b -0, g-1, r-2 \n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    # At the bottom of the image, imshape[0] and top has been defined as 330\n",
    "    imshape = img.shape \n",
    "    \n",
    "    slope_left=0\n",
    "    slope_right=0\n",
    "    leftx=0\n",
    "    lefty=0\n",
    "    rightx=0\n",
    "    righty=0\n",
    "    i=0\n",
    "    j=0\n",
    "    \n",
    "    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            if slope >0.1: #Left lane and not a straight line\n",
    "                # Add all values of slope and average position of a line\n",
    "                slope_left += slope \n",
    "                leftx += (x1+x2)/2\n",
    "                lefty += (y1+y2)/2\n",
    "                i+= 1\n",
    "            elif slope < -0.2: # Right lane and not a straight line\n",
    "                # Add all values of slope and average position of a line\n",
    "                slope_right += slope\n",
    "                rightx += (x1+x2)/2\n",
    "                righty += (y1+y2)/2\n",
    "                j+= 1\n",
    "    # Left lane - Average across all slope and intercepts\n",
    "    if i>0: # If left lane is detected\n",
    "        avg_slope_left = slope_left/i\n",
    "        avg_leftx = leftx/i\n",
    "        avg_lefty = lefty/i\n",
    "        # Calculate bottom x and top x assuming fixed positions for corresponding y\n",
    "        xb_l = int(((int(0.97*imshape[0])-avg_lefty)/avg_slope_left) + avg_leftx)\n",
    "        xt_l = int(((int(0.61*imshape[0])-avg_lefty)/avg_slope_left)+ avg_leftx)\n",
    "\n",
    "    else: # If Left lane is not detected - best guess positions of bottom x and top x\n",
    "        xb_l = int(0.21*imshape[1])\n",
    "        xt_l = int(0.43*imshape[1])\n",
    "    \n",
    "    # Draw a line\n",
    "    cv2.line(img, (xt_l, int(0.61*imshape[0])), (xb_l, int(0.97*imshape[0])), color, thickness)\n",
    "    \n",
    "    #Right lane - Average across all slope and intercepts\n",
    "    if j>0: # If right lane is detected\n",
    "        avg_slope_right = slope_right/j\n",
    "        avg_rightx = rightx/j\n",
    "        avg_righty = righty/j\n",
    "        # Calculate bottom x and top x assuming fixed positions for corresponding y\n",
    "        xb_r = int(((int(0.97*imshape[0])-avg_righty)/avg_slope_right) + avg_rightx)\n",
    "        xt_r = int(((int(0.61*imshape[0])-avg_righty)/avg_slope_right)+ avg_rightx)\n",
    "    \n",
    "    else: # If right lane is not detected - best guess positions of bottom x and top x\n",
    "        xb_r = int(0.89*imshape[1])\n",
    "        xt_r = int(0.53*imshape[1])\n",
    "    \n",
    "    # Draw a line    \n",
    "    cv2.line(img, (xt_r, int(0.61*imshape[0])), (xb_r, int(0.97*imshape[0])), color, thickness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 5\n",
    "Gauss_img = cv2.GaussianBlur(patch_image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "low_threshold = 50\n",
    "high_threshold = 150\n",
    "canny_edges = cv2.Canny(Gauss_img, low_threshold, high_threshold)\n",
    "imshape = canny_edges.shape\n",
    "vertices = np.array([[(int(0.21*imshape[1]),imshape[0]),(int(0.44*imshape[1]), int(0.59*imshape[0])), (int(0.50*imshape[1]), int(0.59*imshape[0])), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "\n",
    "img_with_Roi = region_of_interest(canny_edges,vertices)\n",
    "\n",
    "lines = cv2.HoughLinesP(img_with_Roi, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "draw_lines(line_img, lines)\n",
    "\n",
    "Show_Image(img_with_Roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
